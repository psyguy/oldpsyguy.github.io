# Residual Structural Equation Modeling --- A short sketch
### MH Manuel Haqiqatkhah

---

## Intro

This document is an informal introduction to---and a subsequent literature review of---[residual] dynamic structural equation modeling ([R]DSEM) and an implementation of a simple case of it using R package `lavaan`. Without some [basic knowledge of factor analysis](https://en.wikipedia.org/wiki/Factor_analysis)---or, SEM with latent variables/measurement models---the reader might find the text a bit cryptic. Nonetheless, I will review the matter. Let's first review how FA/SEM works in non-longitudinal data.

### Conventional R-factor analysis

Latent variable modeling (LVM) tries to estimate a (multidimensional) latent construct---AKA *factor*---that is believed to have "caused" the variations obsereved in a measurement made on a sample. This factor need not actually exist; it can be an abstract reification of processes involved in generating the variations observed in the data, and one need not make any ontological commitments to their actual existence---what does it mean to exist by the way?

I know many psychmetricians/psychologists/philosophers would disagree with what I just mentioned. I believe this disagreement (at least partly) lies in the definition of (ontological) existence and causality. I take on a mechanistic approach towards explanation of phenomenon (as discussed in my master thesis in AI, which I will link it here when I publish it online) and with my interpretation of "vertical causation".


Anyways.

The classic case of LVM is R-factor analysis, wherein cross-sectional measurements of $n$ variables in a sample of $N$ individuals is analyzed to find out whether some (abstract) "entities" (i.e., factors) can explain the variations between the data collected from the individuals.






The problem is as follows.

Suppose you have collected some intensive longitudinal data of a participant and now you have an $n$-dimensional multivariate time series, say, $Y_{t_{n \times 1}} = [y^1_{t}, y^2_{t}, \ldots, y^n_{t}]^\top$ at time $t$. Now you want to model the $m$-dimensional latent constructs 'causing' the measured values, i.e., $\Theta_{t_{m \times 1}} = [\theta^1_{t}, \theta^2_{t}, \ldots, \theta^m_{t}]^\top$. You can write a factor model for each time as

$$Y_t = \Lambda_t \Theta_t + E_t$$

Where the loading matrix $\Lambda_{t_{n \times m}}$ is the factor loadings of your manifest variables (known in the context of psychometrics as _items_) on the latent variables (i.e., _factors_). The vector $E_{t_{n \times 1}} = [\epsilon^1_{t}, \epsilon^2_{t}, \ldots, \epsilon^n_{t}]^\top$, usually referred to as _meassurement errors_, is basically the residuals terms of the system of linear regressions describing the factor model. $E_{t_{n \times 1}}$ encapsulates the unexplained variations of items that the factor model could not capture, and are usually assumed to be normally distributed. More formally, $E_t \sim \mathcal{N}(0, \Psi_t)$. $\Psi_t$ is the covariance matrix of the residuals.

Let the covariance matrix of the latent variables be $\Phi_t$. In order to estimate the factor loadings $\Lambda_t$, the covariance structure implied by the model, i.e.,

$$\Sigma_t = \Lambda_t \Phi_t \Lambda_t^\top + \Psi_t$$

is compare to the actual covariance matrix of measurements, $S_t$, and maximum likelihood estimates $\Sigma_t$ by minimizing the fit function

$$$$


which allows us to calculate the  estimate the loading matrix  by solving the following 


The current model, as is, assumes tha

To illustrate my solution, suppose that at each measurement time $t$, we have a vector of manifest variables  and a vector of latent variables ,  such that 

If the data is generated by a Markov process of lag $\gamma$, one can assume that the $\gamma$-back serial dependency caused at the factor level, such that

$$P(\Theta_{t}|\Theta_{t-1}, \Theta_{t-2}, \ldots, \Theta_{1}) = P(\Theta_{t}|\Theta_{t-1}, \ldots,\Theta_{t-\gamma})$$


## A short literature review

Most of the research in this area (at least those enumerated here) belong to psychology and social sciences.

- A) Hamaker, E. L., Asparouhov, T., Brose, A., Schmiedek, F., & Muthén, B. (2018). **At the frontiers of modeling intensive longitudinal data: Dynamic structural equation models for the affective measurements from the COGITO study**. Multivariate behavioral research, 1-22. https://doi.org/10.1080/00273171.2018.1446819

- B) Driver, C. C., Oud, J. H., & Voelkle, M. C. (2017). **Continuous time structural equation modeling with R package ctsem**. http://dx.doi.org/10.18637/jss.v077.i05

- C) Driver, C. C., & Voelkle, M. C. (2017). **Introduction to Hierarchical Continuous Time Dynamic Modelling With ctsem**. R package Vignette. Available online at: https://cran.r-project.org/web/packages/ctsem/index.html.

- D) Driver, C. C. (2018). **Hierarchical Continuous Time Dynamic Modelling for Psychology and the Social Sciences**. https://doi.org/10.18452/18927

- E) McNeish, D. (2018). **A Primer on Two-Level Dynamic Structural Equation Models for Intensive Longitudinal Data**. https://doi.org/10.31234/osf.io/j56bm

- F) Asparouhov, T., Hamaker, E. L., & Muthén, B. (2018). **Dynamic structural equation models**. Structural Equation Modeling: A Multidisciplinary Journal, 25(3), 359-388. https://doi.org/10.1080/10705511.2017.1406803
	
- G) Asparouhov, T., & Muthén, B. (2019). **Comparison of models for the analysis of intensive longitudinal data**. http://www.statmodel.com/download/RDSEM.pdf
	
- H) Poncela, P., & Ruiz, E. (2012). **More is not always better: back to the Kalman filter in dynamic factor models**. https://www.ucm.es/data/cont/docs/518-2013-11-05-Poncela_Jun4.pdf
	
- I) McAlinn, K., Rockova, V., & Saha, E. (2018). **Dynamic Sparse Factor Analysis**. arXiv preprint arXiv:1812.04187. https://arxiv.org/abs/1812.04187
	
- J) Holmes, E. E., Scheuerell, M. D., and Ward, E. J. (2019). **Applied Time Series Analysis for Fisheries and Environmental Sciences**. https://nwfsc-timeseries.github.io/atsa-labs/
	
- K) Bianconcini, S., & Bollen, K. A. (2018). **The Latent Variable-Autoregressive Latent Trajectory Model: A General Framework for Longitudinal Data Analysis**. Structural Equation Modeling: A Multidisciplinary Journal, 25(5), 791-808. https://doi.org/10.1080/10705511.2018.1426467
	
- L) Hamaker, E. L., Dolan, C. V., & Molenaar, P. C. (2003). **ARMA-based SEM when the number of time points T exceeds the number of cases N: Raw data maximum likelihood**. Structural Equation Modeling, 10(3), 352-379. https://doi.org/10.1207/S15328007SEM1003_2

- M) Voelkle, M. C., Oud, J. H., von Oertzen, T., & Lindenberger, U. (2012). **Maximum likelihood dynamic factor modeling for arbitrary N and T using SEM**. Structural Equation Modeling: A Multidisciplinary Journal, 19(3), 329-350. https://doi.org/10.1080/10705511.2012.687656

- N) Molenaar, P. C., & Nesselroade, J. R. (2009). **The recoverability of P-technique factor analysis**. Multivariate Behavioral Research, 44(1), 130-141. https://doi.org/10.1080/00273170802620204

### A quick review of these references:

**A** lacks the measurement model and consequently does not take into account AR at measurement level. [Mplus]

**B**, **C**, belong to ctsem R package developed in **D**, which is Driver's Ph.D. dissertation. Driver claims ctsem is capable of dynamic factor analysis. However, the suggested measurement model assumes serial independence of manifest residuals (in contrast to, e.g., RDSEM). So this cannot be used in our problem. (Driver and I [had a discussion on twitter.](https://twitter.com/_psyguy/status/1118794063472361472)) [R]

**E** briefly addresses the trended data but lacks measurement model (and consequently, residual AR). [Mplus]

**F** is a (rather comprehensive) tutorial to DSEM which also (rather briefly) addresses RDSEM. It has an appendix on RDSEM estimation which helps better understand the model. In short, they break down the error/residual term and consequently form "a special case of the DSEM model where the residual variables are modeled as within-level latent variables." [Mplus]

**G** is a better, more detailed comparison of DSEM and RDSEM. [Mplus]

**H** and **I** are good texts explaining DFMs. The former discusses the role of serial and contemporaneous idiosyncratic noise (~ residuals in RDSEM context) and how to include it in the model. [R]

**J** discusses DFM in more details with additional examples in R but doesn't go deep in residual AR as far as I've noticed. [R]

**K** is a great reference discussing building such AR models (as called Latent Variable-Autoregressive Latent Trajectory, LV-ALT models). [no implementation]

**L** is an interesting case of ARMA (D)SEM but still does not moel residual temporal dependencies. [Mx]

**M**, good to be comapre with **L**, is an integration of two approaches: "standard time series analysis (T large and N = 1) and conventional SEM (N large and T = 1 or small)," and addresses ergodicity too. It does not model residual serial dependencies however. [OpenMx]

Finally, one should also cf. **N** for evidence supporting robustness of P-factor analysis in time series of affect. If this is true for a multivariate time series, one does not need to deal with complicated (D)SEM models. [Nonlis] 

## The solution

In short, the RDSEM can be modeled by structuring the covariance structure of residuals.


This is the assumption behind ordinary DSEMs. However, it is quite possible that the measurement residuals of manifest variables have (autoregressive) serial dependencies, i.e.,

$$corr(\epsilon^i_{t_l}, \epsilon^i_{t_l+1 \lt t \leq t_l+\gamma}) \neq 0$$

If that is the case, the data should be modeled by residual DSEM (RDSEM) since the assumption of independence of manifest residuals is violated.

A simple solution is to make a new time series of $\Upsilon$ with $(\gamma+1)$-fold dimentionality:

$$\Upsilon_{(\gamma+1)*n \times 1} = [Y_{t-\gamma}, \ldots,Y_{t}]^\top$$

And models a new factor model

$$\Omega_{(\gamma+1)*m \times 1} = [\Theta_{t-\gamma}, \ldots, \Theta_{t}]^\top$$

The model can be then identified by estimation of the following loading tensor, where the off-diagonal matricies are zero:

$$\Pi_{(\gamma+1)*n \times (\gamma+1)*m} =
\begin{bmatrix} 
\Lambda_{t-\gamma} & 0 & \ldots & 0 \\
0 & \Lambda_{t-\gamma+1} & \ldots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \Lambda_{t}
\end{bmatrix}$$

With the following 

Under the assumption of stationarity, 

On the 

If there is no cross-lagegd serial dependejncies Which can be estimated 

The RDSEM, for the case of $\gamma = 1$ can be simply modeled with the following 


However, the manifest variables (at the item level) are (highly) autocorrelated, meaning that I cannot basically assume error independence, so in general $corr(\epsilon^i_{t}, \epsilon^j_{t}) \neq 0$. As a result, I have to take the autocorrelation of errors into account.



**My solution was** to make a new time series of consecutive observations $\Upsilon_{2n \times 1} = [Y_{t-1},Y_{t}]^T$, and as a result, I will have a new vector of factors . I further assume measurement invariance accross time (i.e., $\Lambda_t = \Lambda$). Hence, I will have a new loading matrix 

